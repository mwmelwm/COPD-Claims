# Load required libraries
library(tidyverse)
library(caret)
library(glmnet)
library(randomForest)
library(pROC)
library(e1071)
library(ggplot2)
library(corrplot)
library(DMwR)  
library(fastDummies)
library(purrr)

#-----------------------------------------------
# 1. Data Loading and Exploration
#-----------------------------------------------

# Read in data
claims <- read.csv("COPD_MED.csv", stringsAsFactors = TRUE)

# Data exploration
str(claims)
summary(claims)

#-----------------------------------------------
# 1. Data Cleaning and Preprocessing
#-----------------------------------------------

# Convert year/month to year/month/date
claims$MONTH <- as.Date(paste(claims$MONTH, "01", sep = "/"))

# Remove variables that won't be used after doing research
claims <- claims %>%
  select(-c(SERVICE_CNT, PRIMARY_ICD_DX_DESC, CPT4_DESC))

# Drop patients under age 18 since these patients are outliers
claims <- claims %>%
  filter(!AGE_RANGE %in% c("1 - 9", "10 - 17"))

# Handle missing data with imputation
preprocess_params <- preProcess(claims, method = c("medianImpute"))
claims <- predict(preprocess_params, claims)

# Categorize claims
categorize_claims <- function(icd10_code) {
  case_when(
    grepl("^J4[0-7]", icd10_code) ~ "COPD",
    grepl("^J", icd10_code) ~ "Respiratory Non COPD",
    TRUE ~ "Non Respiratory"
  )
}

claims <- claims %>%
  mutate(claim_category = categorize_claims(ICD10.1)) %>%
  filter(!grepl("^S|T|V|W|X|Y", ICD10.1))

#-----------------------------------------------
# 2. Initial Exploratory Data Analysis (EDA)
#-----------------------------------------------

# Age Distribution
ggplot(claims, aes(x = AGE_RANGE)) +
  geom_bar(fill = "lightblue", color = "black") +
  theme_minimal() +
  labs(title = "Age Distribution of Patients", x = "Age Range", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Gender Distribution
ggplot(claims, aes(x = GENDER_CODE)) +
  geom_bar(fill = "lightgreen", color = "black") +
  theme_minimal() +
  labs(title = "Gender Distribution of Patients", x = "Gender", y = "Count")

# Area Deprivation Index Distribution
ggplot(claims, aes(x = AREA_DEPRIV_INDEX)) +
  geom_histogram(binwidth = 2, fill = "lightyellow", color = "black") +
  theme_minimal() +
  labs(title = "Area Deprivation Index Distribution", x = "AREA_DEPRIV_INDEX", y = "Count")

# Line of Business Distribution
ggplot(claims, aes(x = LOB)) +
  geom_bar(fill = "lightpink", color = "black") +
  theme_minimal() +
  labs(title = "Line of Business Distribution", x = "LOB", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Service Location Distribution
ggplot(claims, aes(x = HIAA_POS_DESC)) +
  geom_bar(fill = "lightcoral", color = "black") +
  theme_minimal() +
  labs(title = "Service Location Distribution", x = "Service Location", y = "Count") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

# Claim Category Distribution
ggplot(claims, aes(x = claim_category)) +
  geom_bar(fill = "lightskyblue", color = "black") +
  theme_minimal() +
  labs(title = "Claim Category Distribution", x = "Claim Category", y = "Count")

#-----------------------------------------------
# 3. Feature Engineering 
#-----------------------------------------------

# Find code that is associated with the emergency room
ED_FIN_SUB_CAT <- 200210
ED_HIAA_code <- 23

# Function to create predictors for each patient
createPredictors <- function(df) {
  start <- max(df$MONTH)
  end <- min(df$MONTH)
  pred <- start + 730
  
  x <- filter(df, MONTH > start, MONTH <= pred)
  y <- filter(df, MONTH > pred, MONTH <= end)
  
  out <- df[1, c("UNIQUE_ID", "LOB", "GENDER_CODE", "AGE_RANGE", "DECEASED", "TERMED", "AREA_DEPRIV_INDEX",)]
  
  out$COPD_ED_X <- sum(x$HIAA_POS_CODE == ED_HIAA_code & 
                       x$FINANCIAL_SERVICE_SUBGRP_CODE == ED_FIN_SUB_CAT & 
                       x$claim_category == "COPD")
  
  out$ED_X <- sum(x$HIAA_POS_CODE == ED_HIAA_code & 
                  x$FINANCIAL_SERVICE_SUBGRP_CODE == ED_FIN_SUB_CAT)
  
  out$ED_Y <- sum(y$HIAA_POS_CODE == ED_HIAA_code & 
                  y$FINANCIAL_SERVICE_SUBGRP_CODE == ED_FIN_SUB_CAT)
  
  out$TOTAL_CLAIMS_X <- nrow(x)
  out$RESPIRATORY_CLAIMS_X <- sum(x$claim_category %in% c("COPD", "Respiratory Non COPD"))
  out$UNIQUE_DIAGNOSES_X <- length(unique(x$ICD10.1))
  

  
  out
}

# Apply createPredictors function to each patient
patients <- claims %>%
  split(.$UNIQUE_ID) %>%
  map_dfr(createPredictors)

# Transform ED_Y to binary response variable
patients$ED_Y <- factor(ifelse(patients$ED_Y < 10, "NonCostly", "Costly"))

# Remove unnecessary columns
data <- patients %>%
  select(-c(UNIQUE_ID, DECEASED, TERMED, START_DATE, END_DATE, PRED_DATE))

#-----------------------------------------------
# 4. Comprehensive EDA (including engineered features)
#-----------------------------------------------

# Correlation matrix of numeric variables
numeric_cols <- sapply(data, is.numeric)
correlation_matrix <- cor(data[, numeric_cols])
corrplot(correlation_matrix, method = "circle")

# Distribution of dependent variable
ggplot(data, aes(x = ED_Y)) +
  geom_bar(fill = "lightblue", color = "black") +
  theme_minimal() +
  labs(title = "Distribution of Costly vs Non-Costly Patients", x = "ED_Y", y = "Count")

# Boxplots of numeric variables by ED_Y
numeric_vars <- names(data)[sapply(data, is.numeric)]
for (var in numeric_vars) {
  ggplot(data, aes_string(x = "ED_Y", y = var)) + 
    geom_boxplot() + 
    theme_minimal() + 
    labs(title = paste("Distribution of", var, "by ED_Y"), y = var)
}

# Histogram of Total Claims
ggplot(data, aes(x = TOTAL_CLAIMS_X)) +
  geom_histogram(binwidth = 10, fill = "lightgreen", color = "black") +
  theme_minimal() +
  labs(title = "Distribution of Total Claims", x = "Total Claims", y = "Count")

# Scatter plot of ED visits vs Total Claims
ggplot(data, aes(x = TOTAL_CLAIMS_X, y = ED_X, color = ED_Y)) +
  geom_point(alpha = 0.5) +
  theme_minimal() +
  labs(title = "ED Visits vs Total Claims", x = "Total Claims", y = "ED Visits")

#-----------------------------------------------
# 5. Final Preprocessing
#-----------------------------------------------

# Handle outliers
handle_outliers <- function(x) {
  qnt <- quantile(x, probs=c(.25, .75), na.rm = TRUE)
  H <- 1.5 * IQR(x, na.rm = TRUE)
  x[x < (qnt[1] - H)] <- qnt[1] - H
  x[x > (qnt[2] + H)] <- qnt[2] + H
  x
}

data <- data %>%
  mutate_if(is.numeric, handle_outliers)

# Identify categorical and continuous features
categorical_features <- c("AGE_RANGE", "GENDER_CODE", "LOB", "HIAA_POS_DESC")
continuous_features <- setdiff(names(data), c(categorical_features, "ED_Y"))

# One-hot encode categorical features
data_encoded <- dummy_cols(data, select_columns = categorical_features, remove_selected_columns = TRUE)

#-----------------------------------------------
# 6. Modeling
#-----------------------------------------------

# Split data into train and test sets
set.seed(42)
train_index <- createDataPartition(data_encoded$ED_Y, p = 0.7, list = FALSE)
train_data <- data_encoded[train_index, ]
test_data <- data_encoded[-train_index, ]

# Handle class imbalance using SMOTE
train_data_balanced <- SMOTE(ED_Y ~ ., data = train_data, perc.over = 200, perc.under = 100)

# Normalize numerical features
preprocess_params <- preProcess(train_data_balanced[, continuous_features], method = c("center", "scale"))
train_data_norm <- predict(preprocess_params, train_data_balanced)
test_data_norm <- predict(preprocess_params, test_data)

# Function to evaluate model performance
evaluate_model <- function(predictions, probabilities, actual, model_name) {
  confusion_matrix <- confusionMatrix(predictions, actual)
  auc_score <- auc(roc(actual, probabilities))
  
  list(
    model = model_name,
    accuracy = confusion_matrix$overall["Accuracy"],
    sensitivity = confusion_matrix$byClass["Sensitivity"],
    specificity = confusion_matrix$byClass["Specificity"],
    auc = auc_score
  )
}

# Logistic Regression with regularization
cv_model <- cv.glmnet(as.matrix(train_data_norm %>% select(-ED_Y)), 
                      train_data_norm$ED_Y, 
                      family = "binomial", 
                      alpha = 0.5,
                      nfolds = 5)
best_lambda <- cv_model$lambda.min

logistic_pred <- predict(cv_model, newx = as.matrix(test_data_norm %>% select(-ED_Y)), s = best_lambda, type = "class")
logistic_prob <- predict(cv_model, newx = as.matrix(test_data_norm %>% select(-ED_Y)), s = best_lambda, type = "response")

logistic_results <-evaluate_model(as.factor(logistic_pred), as.vector(logistic_prob), test_data$ED_Y, "Logistic Regression")

# Random Forest with hyperparameter tuning
rf_grid <- expand.grid(
  mtry = c(3, 5, 7),
  ntree = c(300, 500, 700)
)

rf_control <- trainControl(method = "cv", number = 5, search = "grid")

rf_tuned <- train(ED_Y ~ ., 
                  data = train_data_norm, 
                  method = "rf",
                  trControl = rf_control,
                  tuneGrid = rf_grid)

rf_pred <- predict(rf_tuned, newdata = test_data_norm)
rf_prob <- predict(rf_tuned, newdata = test_data_norm, type = "prob")[, "Costly"]

rf_results <- evaluate_model(rf_pred, rf_prob, test_data$ED_Y, "Random Forest")

# Check for overfitting
train_pred <- predict(rf_tuned, newdata = train_data_norm)
train_accuracy <- mean(train_pred == train_data_norm$ED_Y)
test_accuracy <- mean(rf_pred == test_data$ED_Y)

print(paste("Train Accuracy:", train_accuracy))
print(paste("Test Accuracy:", test_accuracy))
print(paste("Difference:", train_accuracy - test_accuracy))

# SVM model with hyperparameter tuning
svm_grid <- expand.grid(
  C = c(0.1, 1, 10),
  sigma = c(0.01, 0.1, 1)
)

svm_control <- trainControl(method = "cv", number = 5, search = "grid")

svm_tuned <- train(ED_Y ~ ., 
                   data = train_data_norm, 
                   method = "svmRadial",
                   trControl = svm_control,
                   tuneGrid = svm_grid)

svm_pred <- predict(svm_tuned, newdata = test_data_norm)
svm_prob <- predict(svm_tuned, newdata = test_data_norm, type = "prob")[, "Costly"]

svm_results <- evaluate_model(svm_pred, svm_prob, test_data$ED_Y, "SVM")

# Compare model performance
model_performance <- rbind(
  data.frame(logistic_results),
  data.frame(rf_results),
  data.frame(svm_results)
)

print(model_performance)

# Visualization of model performance
ggplot(model_performance %>% pivot_longer(cols = -model, names_to = "Metric", values_to = "Value"), aes(x = model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Metric, scales = "free_y") +
  theme_minimal() +
  labs(title = "Model Performance Comparison", y = "Score", x = "Model") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Feature importance analysis (for Random Forest)
rf_importance <- varImp(rf_tuned)
feature_significance <- data.frame(
  Feature = rownames(rf_importance$importance),
  Importance = rf_importance$importance[, "Overall"]
)
feature_significance <- feature_significance[order(-feature_significance$Importance), ]

print(feature_significance)

# Visualize feature importance
ggplot(feature_significance[1:10, ], aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Top 10 Most Important Features", x = "Feature", y = "Importance") +
  theme_minimal()

# Partial dependence plots for top features
top_features <- feature_significance$Feature[1:3]
lapply(top_features, function(feature) {
  partialPlot(rf_tuned$finalModel, train_data_norm, feature, "Costly", 
              main = paste("Partial Dependence Plot -", feature))
})


